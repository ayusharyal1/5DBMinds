{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Converting categorical data into numbers with Pandas and Scikit-learn\n",
    "#feature extraction. \n",
    "#When it involves a lot of manual work, this is often referred to as feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import *\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy as sp\n",
    "import nltk.stem\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string\n",
    "from collections import Counter\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>PublicationDate</th>\n",
       "      <th>AppSize</th>\n",
       "      <th>Name</th>\n",
       "      <th>ContentRating</th>\n",
       "      <th>LastUpdateDate</th>\n",
       "      <th>Instalations</th>\n",
       "      <th>IsTopDeveloper</th>\n",
       "      <th>HaveInAppPurchases</th>\n",
       "      <th>IsFree</th>\n",
       "      <th>Developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NEWS_AND_MAGAZINES</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Read the most popular newspapers from  Sweden ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-08T03:00:00.000Z</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Sweden News</td>\n",
       "      <td>Everyone 10+</td>\n",
       "      <td>2015-07-08T03:00:00.000Z</td>\n",
       "      <td>50 - 100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>News Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MEDIA_AND_VIDEO</td>\n",
       "      <td>2.882353</td>\n",
       "      <td>Sweden Tv channels guide. Tv Sweden include lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-25T03:00:00.000Z</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Tv Sweden</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2015-07-25T03:00:00.000Z</td>\n",
       "      <td>5,000 - 10,000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>QSC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            Category     Score  \\\n",
       "0           0  NEWS_AND_MAGAZINES  5.000000   \n",
       "1           1     MEDIA_AND_VIDEO  2.882353   \n",
       "\n",
       "                                         Description  Price  \\\n",
       "0  Read the most popular newspapers from  Sweden ...      0   \n",
       "1  Sweden Tv channels guide. Tv Sweden include lo...      0   \n",
       "\n",
       "            PublicationDate  AppSize         Name ContentRating  \\\n",
       "0  2015-07-08T03:00:00.000Z      2.9  Sweden News  Everyone 10+   \n",
       "1  2015-07-25T03:00:00.000Z      2.8    Tv Sweden      Everyone   \n",
       "\n",
       "             LastUpdateDate    Instalations IsTopDeveloper HaveInAppPurchases  \\\n",
       "0  2015-07-08T03:00:00.000Z        50 - 100          False              False   \n",
       "1  2015-07-25T03:00:00.000Z  5,000 - 10,000          False              False   \n",
       "\n",
       "  IsFree Developer  \n",
       "0   True  News Now  \n",
       "1   True       QSC  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_file = '../data/big-data-csv.csv'\n",
    "appdf = pd.read_csv(app_file,sep=',')\n",
    "appdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NEWS_AND_MAGAZINES\n",
       "1       MEDIA_AND_VIDEO\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_cat = appdf.Category\n",
    "col_cat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples 100000\n"
     ]
    }
   ],
   "source": [
    "#Total Number of Columns:\n",
    "print(\"n_samples\"),max(appdf.index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Category',\n",
       " 'Score',\n",
       " 'Description',\n",
       " 'Price',\n",
       " 'PublicationDate',\n",
       " 'AppSize',\n",
       " 'Name',\n",
       " 'ContentRating',\n",
       " 'LastUpdateDate',\n",
       " 'Instalations',\n",
       " 'IsTopDeveloper',\n",
       " 'HaveInAppPurchases',\n",
       " 'IsFree',\n",
       " 'Developer']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appdf.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEWS_AND_MAGAZINES', 'MEDIA_AND_VIDEO', 'ENTERTAINMENT', 'FINANCE',\n",
       "       'MUSIC_AND_AUDIO', 'TRAVEL_AND_LOCAL', 'EDUCATION', 'BUSINESS',\n",
       "       'PERSONALIZATION', 'TRANSPORTATION', 'SPORTS', 'SOCIAL',\n",
       "       'COMMUNICATION', 'PHOTOGRAPHY', 'LIFESTYLE', 'HEALTH_AND_FITNESS',\n",
       "       'TOOLS', 'PRODUCTIVITY', 'WEATHER', 'BOOKS_AND_REFERENCE',\n",
       "       'GAME_TRIVIA', 'MEDICAL', 'GAME_PUZZLE', 'GAME_CASUAL', 'SHOPPING',\n",
       "       'GAME_MUSIC', 'GAME_ACTION', 'GAME_ARCADE', 'GAME_SIMULATION',\n",
       "       'GAME_CARD', 'GAME_CASINO', 'LIBRARIES_AND_DEMO',\n",
       "       'GAME_EDUCATIONAL', 'GAME_SPORTS', 'GAME_WORD', 'GAME_RACING',\n",
       "       'GAME_ROLE_PLAYING', 'GAME_BOARD', 'COMICS', 'GAME_STRATEGY',\n",
       "       'GAME_ADVENTURE'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_cat.unique())\n",
    "col_cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        \n",
    "        lowers = doc.lower()\n",
    "        doc = lowers.translate(None, string.punctuation) ##remove the punctuation using the character\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "#example, vect = CountVectorizer(tokenizer=LemmaTokenizer()) \n",
    "\n",
    "best_doc = None\n",
    "best_i = None\n",
    "\n",
    "'''Computes eculidean distance between two normalized vectors v1 and v2'''\n",
    "def dist_norm(v1,v2):\n",
    "    v1_normalized = v1/sp.linalg.norm(v1.toarray())\n",
    "    v2_normalized = v2/sp.linalg.norm(v2.toarray())\n",
    "    delta= v1_normalized - v2_normalized\n",
    "    return sp.linalg.norm(delta.toarray()) #norm() calculates the Eculidean norm i.e. shortest distance\"\n",
    "\n",
    "def best_match(column_vectorizer, fmatrix,text_to_compare):\n",
    "    n_samples = 100 # fmatrix.shape[0]\n",
    "    best_dist = sys.maxint\n",
    "    vect_to_compare = column_vectorizer.transform(text_to_compare)\n",
    "    for i in range(0, n_samples):\n",
    "        text_in_column = col_cat[i]\n",
    "        if text_in_column == text_to_compare[0]:\n",
    "            continue\n",
    "        vector_for_column_text = fmatrix.getrow(i)\n",
    "        #d = dist_raw(post_vec, new_post_vec)\n",
    "        d = dist_norm(vector_for_column_text, vect_to_compare)\n",
    "        print \"===Category of app- %i with dist = %.2f: %s\"%(i,d,text_in_column)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_i = i\n",
    "    print \"Best text in category is %i with dist = %.4f\"%(best_i,best_dist)\n",
    "print type([col_cat[4]])\n",
    "#best_match(column_vectorizer,fmatrix, [col_cat[4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Use StemmedCountVectorizer to do:\n",
    "1. lower casing the raw post in the preprossing step done in parent calss.\n",
    "2. Extracting all individual words in the tokenization step in parent class.\n",
    "3. Converting each word into its stemmed version.'''\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "\n",
    "    ##overiding the analyzer of CountVectorizer\n",
    "    def build_analyzer(self):\n",
    "        english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "        analyzer = super(StemmedCountVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "def stat_vectorized_matrix(vectorized_array,vectorizer_type=None):\n",
    "   \n",
    "    #count the number of features generated,\n",
    "    m, n = vectorized_array.shape\n",
    "    count_non_zero_cells = np.count_nonzero(vectorized_array) #vectorized_array.nnz\n",
    "    print(\"vectorizer_type:\"),type(column_vectorizer)\n",
    "    print(\"Sparse matrix shape: \"), vectorized_array.shape\n",
    "    #count the number of non-zero entries,\n",
    "    print(\"Sparsity(%%of non-zero values): %.6f %%\" %(count_non_zero_cells/float(m*n) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Install Stop Words ?\n",
    "\n",
    "    In your terminal:\n",
    "                    $python\n",
    "                    >>import nltk\n",
    "                    >>nltk.download()\n",
    "                    >>d ##hit 'd'\n",
    "                    >>stopwords ##type stopwords\n",
    "    Suppose you downloaded the stopwords in your '~/nltk_data/corpora/stopwords' folder\n",
    "            1. Perhaps the folder is downloaded in your current directory ~/nltk_data/corpora/stopwords\n",
    "            2. Extract 5DBMinds/data/stopwords-extended.zip of our project repository in github.\n",
    "            3. Copy all files to your ~/nltk_data/corpora/stopwords folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Returns a vectorized ND dataframe, vectorized ndarray, \n",
    "and an instance of the vectorizer Class used to transform.'''\n",
    "\n",
    "def vectorize_column(dataframe,column_name,vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        print(\"No Vectorizer is explicitly specified. Using CountVectorizer as default one. \")\n",
    "        column_vectorizer = CountVectorizer(min_df=1)\n",
    "    else:\n",
    "        column_vectorizer = vectorizer\n",
    "    \n",
    "    if column_name in dataframe.columns.values.tolist():\n",
    "        column_df = dataframe[column_name] #select all the samples from the column passed as param.\n",
    "        fmatrix = column_vectorizer.fit_transform(column_df) #convert text features to numerical vectors\n",
    "        dataframe_f = pd.DataFrame(fmatrix.toarray(), columns=column_vectorizer.get_feature_names())\n",
    "        print(\"Dataframe shape :(\"),dataframe_f.index.max()+1,\",\", dataframe_f.head(1).shape[1],\")\"\n",
    "        \n",
    "        return dataframe_f, fmatrix, column_vectorizer\n",
    "    else:\n",
    "        print(\"No column found\")\n",
    "        \n",
    "        \n",
    "'''Returns a vectorized (n_samples,n_features) dataframe, matrix and vectorizing object.\n",
    "Parameters:\n",
    "dataframe: pandas dataframe object\n",
    "column_name: name of the column you want to vectorize (a column in above dataframe object)\n",
    "vectorizer= Vectorizer Object, if none then CountVectorizer is used as default. \n",
    "n_samples: number of rows you want to vectorize\n",
    "tf_idf: if True then TF-IDF matrix is returned, else only matrix of term frequency is return.\n",
    "\n",
    "USAGE:\n",
    "stem_vectorizer = StemmedCountVectorizer(encoding='utf-8',\n",
    "                                         min_df =min_df,\n",
    "                                         max_df =max_df,\n",
    "                                         stop_words='english',\n",
    "                                         analyzer='word',\n",
    "                                         lowercase = lowercase)\n",
    "dfx, matrixX, sv = vectorize_columnTfIdf(df, 'my_column',vectorizer=stem_vectorizer, n_samples=100, tf_idf=True)\n",
    "'''\n",
    "\n",
    "def vectorize_columnTfIdf(dataframe,column_name,vectorizer=None, n_samples=None, tf_idf=False):\n",
    "    \n",
    "    more_stopwords  = ['00','000','0000','0003','0004','0004','0005'] \n",
    "    more_stopwords += stopwords.words('english')\n",
    "    more_stopwords += stopwords.words('japanese') \n",
    "    more_stopwords += stopwords.words('chinese')\n",
    "    more_stopwords += stopwords.words('arabic')\n",
    "    more_stopwords += stopwords.words('korean')\n",
    "    more_stopwords += stopwords.words('russian')    \n",
    "    \n",
    "    if vectorizer is None:\n",
    "        print(\"No Vectorizer is explicitly specified. Using CountVectorizer as default one. \")\n",
    "        column_vectorizer = CountVectorizer(min_df=1) #default vectorizer\n",
    "    else:\n",
    "        column_vectorizer = vectorizer\n",
    "        column_vectorizer.stop_words = more_stopwords\n",
    "    \n",
    "    if column_name in dataframe.columns.values.tolist():\n",
    "        \n",
    "        if n_samples is None:\n",
    "            column_df = dataframe[column_name] #select all the samples from the column passed as param. \n",
    "            print len(column_df)\n",
    "        else:\n",
    "            column_df = dataframe[column_name].iloc[0:n_samples] #select all the samples from the column passed as param.\n",
    "            print len(column_df)\n",
    "        \n",
    "        fmatrix = column_vectorizer.fit_transform(column_df)   \n",
    "        \n",
    "        if(tf_idf is True):\n",
    "            \n",
    "            tfidf_transformer  = TfidfTransformer(norm='l2').fit(fmatrix)\n",
    "            tfidfNormalzedmatrix = tfidf_transformer.transform(fmatrix)\n",
    "            fmatrix = tfidfNormalzedmatrix\n",
    "            \n",
    "        dataframe_f = pd.DataFrame(fmatrix.todense(), columns=column_vectorizer.get_feature_names())\n",
    "        print(\"formed dataframe of size:(\"),dataframe_f.index.max()+1,\",\", dataframe_f.head(1).shape[1],\")\"\n",
    "        \n",
    "        return dataframe_f, fmatrix, column_vectorizer\n",
    "    else:\n",
    "        print(\"No column found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove following words:\n",
    "\n",
    "    5. Do capital letters carry information? [Lowercasing]\n",
    "    4. Does distinguishing inflected form (\"goes\" vs. \"go\") carry information?[Stemming/Lemmantizing]\n",
    "    3. Do interjections, determiners carry information (Stop Words)?\n",
    "    2. Does numerical strings carries information? 000, 000, 100 \t000, 0000,000031,0002, 03 ,004,\t0005 \t0006 \t0007\n",
    "    1. \n",
    "####  Term Frequency: \n",
    "    Counting how many times does a word occur in each message (Term Freq.)\n",
    "#### Inverse  Document Frequency:\n",
    "    weighting the counts, so that frequent tokens get lower weight \n",
    "#### Normalization\n",
    "    normalizing the vectors to unit length, to abstract from the original text length (L2 Norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORY\n",
    "#### '''Analysis of 'Category' data-columns\n",
    "##### Each of the application has only one 'category' so the each of the category is equi-distance from all other.\n",
    "Though similarity of each of the values of category is same, the category-name itself might not effect the rating equally.\n",
    "That is why they are inluded as training features.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORY\n",
      "Dataframe shape :( 100000 , 41 )\n",
      "vectorizer_type: <class '__main__.StemmedCountVectorizer'>\n",
      "Sparse matrix shape:  (100000, 41)\n",
      "Sparsity(%of non-zero values): 2.44 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>books_and_refer</th>\n",
       "      <th>busi</th>\n",
       "      <th>comic</th>\n",
       "      <th>communic</th>\n",
       "      <th>educ</th>\n",
       "      <th>entertain</th>\n",
       "      <th>financ</th>\n",
       "      <th>game_act</th>\n",
       "      <th>game_adventur</th>\n",
       "      <th>game_arcad</th>\n",
       "      <th>...</th>\n",
       "      <th>person</th>\n",
       "      <th>photographi</th>\n",
       "      <th>product</th>\n",
       "      <th>shop</th>\n",
       "      <th>social</th>\n",
       "      <th>sport</th>\n",
       "      <th>tool</th>\n",
       "      <th>transport</th>\n",
       "      <th>travel_and_loc</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   books_and_refer  busi  comic  communic  educ  entertain  financ  game_act  \\\n",
       "0                0     0      0         0     0          0       0         0   \n",
       "1                0     0      0         0     0          0       0         0   \n",
       "2                0     0      0         0     0          1       0         0   \n",
       "\n",
       "   game_adventur  game_arcad   ...     person  photographi  product  shop  \\\n",
       "0              0           0   ...          0            0        0     0   \n",
       "1              0           0   ...          0            0        0     0   \n",
       "2              0           0   ...          0            0        0     0   \n",
       "\n",
       "   social  sport  tool  transport  travel_and_loc  weather  \n",
       "0       0      0     0          0               0        0  \n",
       "1       0      0     0          0               0        0  \n",
       "2       0      0     0          0               0        0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Possible type of count vectorizer that could be used.\n",
    "    Examples: \n",
    "    column_vectorizer = CountVectorizer(min_df=1)\n",
    "    column_vectorizer = CountVectorizer(min_df =1, stop_words='english') \n",
    "    print column_vectorizer.get_feature_names()\n",
    "    Do not ASSIGN max_df and min_df if you are using TF-IDF. Because tf-idf considers the case.\n",
    "'''\n",
    "min_df = 1\n",
    "max_df = 0.99 #it's value lies in: [0.7, 1.0), remove the word that occur in more than 90% of all the posts.\n",
    "token_pattern = r\"\\b[a-z]\\b\"\n",
    "lowercase = True\n",
    "stem_vectorizer = StemmedCountVectorizer(encoding='utf-8',\n",
    "                                         min_df =min_df,\n",
    "                                         max_df =max_df,\n",
    "                                         stop_words='english',\n",
    "                                         analyzer='word',\n",
    "                                         lowercase = lowercase)\n",
    "print(\"CATEGORY\")\n",
    "cat_newfeature, cat_fmatrix, cat_column_vectorizer = vectorize_column(appdf, 'Category', stem_vectorizer)\n",
    "stat_vectorized_matrix(cat_fmatrix.toarray(), column_vectorizer)\n",
    "#print len(column_vectorizer.vocabulary_) #vocabulary_ is feature set.\n",
    "cat_newfeature.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TD-IDF Transformer, Also\n",
    "    1. Evaluate change in sparcity. No change in sparcity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_tfidf_transformer  = TfidfTransformer().fit(cat_fmatrix)\n",
    "cat_nd_array_x = cat_tfidf_transformer.transform(cat_fmatrix.toarray(), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer_type: <class '__main__.StemmedCountVectorizer'>\n",
      "Sparse matrix shape:  (100000, 41)\n",
      "Sparsity(%of non-zero values): 2.44 %\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "stat_vectorized_matrix(cat_nd_array_x.toarray(),cat_tfidf_transformer)\n",
    "\n",
    "print nd_array_x.toarray()[0:10,0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Analysis of Description Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stopwords = stopwords.words('english') #37386, 37225,37185\n",
    "\n",
    "more_stopwords  = ['00','000','0000','0003','0004','0004','0005'] \n",
    "more_stopwords += stopwords.words('english')\n",
    "more_stopwords += stopwords.words('japanese') \n",
    "more_stopwords += stopwords.words('chinese')\n",
    "more_stopwords += stopwords.words('arabic')\n",
    "more_stopwords += stopwords.words('korean')\n",
    "more_stopwords += stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "formed dataframe of size:( 100 , 3210 )\n"
     ]
    }
   ],
   "source": [
    "#token_pattern = r\"\\b[a-z]*\\b\"\n",
    "token_pattern = r\"*\"\n",
    "\n",
    "col_desc = appdf.Description\n",
    "df_desc = pd.DataFrame(col_desc, columns=['Description']).iloc[:]\n",
    "\n",
    "\n",
    "stem_vectorizer = StemmedCountVectorizer(min_df =min_df,\n",
    "                                         max_df= max_df,\n",
    "                                         analyzer='word',\n",
    "                                         stop_words =more_stopwords\n",
    "                                         )\n",
    "newfeature, desc_fmatrix, desc_vectorizer = vectorize_column2(df_desc, 'Description', stem_vectorizer, n_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer_type: <class '__main__.StemmedCountVectorizer'>\n",
      "Sparse matrix shape:  (100, 3210)\n",
      "Sparsity(%of non-zero values): 2.333645 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>044</th>\n",
       "      <th>0771</th>\n",
       "      <th>08</th>\n",
       "      <th>0mrsneradionrjpit</th>\n",
       "      <th>0radiometanasthspmradio</th>\n",
       "      <th>0stockholm</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>örebroradio</th>\n",
       "      <th>örnsköldsvikfeatur</th>\n",
       "      <th>östergötland</th>\n",
       "      <th>östergötlandsverig</th>\n",
       "      <th>österlen</th>\n",
       "      <th>östersund</th>\n",
       "      <th>överraska</th>\n",
       "      <th>övriga</th>\n",
       "      <th>スウェーデンを検索し</th>\n",
       "      <th>壁紙に設定します</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    044  0771  08  0mrsneradionrjpit  0radiometanasthspmradio  0stockholm  10  \\\n",
       "95    0     0   0                  0                        0           0   0   \n",
       "96    0     0   0                  0                        0           0   0   \n",
       "97    0     0   0                  0                        0           0   0   \n",
       "98    0     0   0                  0                        0           0   0   \n",
       "99    0     0   0                  0                        0           0   5   \n",
       "\n",
       "    100  101  102    ...     örebroradio  örnsköldsvikfeatur  östergötland  \\\n",
       "95    2    0    0    ...               0                   0             0   \n",
       "96    0    0    0    ...               0                   0             0   \n",
       "97    0    0    0    ...               0                   0             0   \n",
       "98    0    0    0    ...               0                   0             0   \n",
       "99    0    0    0    ...               0                   0             0   \n",
       "\n",
       "    östergötlandsverig  österlen  östersund  överraska  övriga  スウェーデンを検索し  \\\n",
       "95                   0         0          0          0       0           0   \n",
       "96                   0         0          0          0       0           0   \n",
       "97                   0         0          0          0       0           0   \n",
       "98                   0         0          0          0       0           0   \n",
       "99                   0         0          0          0       0           0   \n",
       "\n",
       "    壁紙に設定します  \n",
       "95         0  \n",
       "96         0  \n",
       "97         0  \n",
       "98         0  \n",
       "99         0  \n",
       "\n",
       "[5 rows x 3210 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_vectorized_matrix(desc_fmatrix.toarray(), desc_vectorizer)\n",
    "newfeature.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer_type: <class '__main__.StemmedCountVectorizer'>\n",
      "Sparse matrix shape:  (100, 3210)\n",
      "Sparsity(%of non-zero values): 2.333645 %\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer  = TfidfTransformer(norm=\"l2\").fit(desc_fmatrix)\n",
    "desc_nd_array_x = tfidf_transformer.transform(desc_fmatrix, copy=True)\n",
    "\n",
    "stat_vectorized_matrix(desc_nd_array_x.todense(),tfidf_transformer)\n",
    "\n",
    "print desc_nd_array_x.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In an average, one cell of a description column generates 57 features. In this way, there are 57*n_samples features geneated after vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Name Field\n",
    "    suggest some of the price for higer number of sale\n",
    "    w1: parameterized loudness of words in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_name = appdf.Name\n",
    "#print col_name[col_name.str.contains('000')]\n",
    "\n",
    "#stem_vectorizer = StemmedCountVectorizer(min_df =1, stop_words='english')\n",
    "#newfeature, fmatrix, column_vectorizer = vectorize_column(appdf, 'Name', stem_vectorizer)\n",
    "#print column_vectorizer.get_feature_names()\n",
    "#newfeature.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of 'Instalations'\n",
    "    It is range values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_name = appdf.Instalations\n",
    "def separate_instalation_column(dataframe, column_name,return_data_type_as=None):\n",
    "    \n",
    "    col_name = appdf[column_name]\n",
    "    ls = col_name.str.split('-').str.get(0).str.strip(' ').str.replace(',','') #series object\n",
    "    hs = col_name.str.split('-').str.get(1).str.strip(' ').str.replace(',','') #series object\n",
    "    \n",
    "    if return_data_type_as is float64:\n",
    "        ls = ls.astype(float).fillna(0.0)\n",
    "        hs = hs.astype(float).fillna(0.0)\n",
    "        return ls, hs\n",
    "    else:\n",
    "        return ls, hs\n",
    "    \n",
    "ls, hs = separate_instalation_column(appdf,'Instalations', float64)\n",
    "appdf.installs_ls = ls\n",
    "appdf.installs_hs = hs\n",
    "print appdf.installs_ls.head(5) + appdf.installs_hs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues:\n",
    "            Tokenization problem\n",
    "            Vectorization problem memory error\n",
    "            Plot the frequency distribution of price \n",
    "            Do linear regression on price and plot Predicted_price-Desired_price Vs Predicted_price\n",
    "            \n",
    "            \n",
    "            http://www.cs.toronto.edu/~marlin/research/thesis/cfmlp.pdf\n",
    "            \n",
    "### FootNotes:\n",
    "    \n",
    "        What does a rater sees when he rates an android app? == Extrinsic Features\n",
    "        What an android app inherits that influences app rating? == Intrinsic Features\n",
    "\n",
    "\n",
    "        Vectors to predict: 1. 5-star count, 4-star count, 3-star-count, 2-star count, 1-star count.\n",
    "        Because, average app-rating depends upon the values of these values. Also on current rating of the app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
