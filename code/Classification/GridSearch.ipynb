{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This program uses scikits gridsearch cv and helps to find the best set of parameters for a classifier. This is \n",
    "# generally used for tuning up the classifier paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as str\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from  datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk.stem\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import AppVectorizerModule as ATV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a gridsearchresult folder\n",
    "resultpath='/home/ayush/Desktop/gsresult/'\n",
    "#resultpath='../gsresult/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to return parameters based on classifier\n",
    "def getParamGrid(clfname):\n",
    "    clfname=getClassifierName(clfname)\n",
    "    param_grid={}\n",
    "    if clfname=='RandomForestClassifier':   \n",
    "        param_grid = { \n",
    "            'n_estimators': [50,100,200,500],\n",
    "            'max_features': [None, 'sqrt', 'log2'],\n",
    "            'criterion' : ['gini','entropy'],\n",
    "            'oob_score' : [True,False],\n",
    "            'random_state' : [0,10,20,30]\n",
    "        }\n",
    "    elif clfname=='DecisionTreeClassifier':\n",
    "        param_grid = { \n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'criterion' : ['gini','entropy'],\n",
    "            'random_state' : [0,10,20,30],\n",
    "            'splitter' : ['random','best']\n",
    "        }\n",
    "    elif clfname=='LinearSVC':\n",
    "        param_grid = { \n",
    "            'tol' : [0.0001,0.0002,0.0003,0.004],\n",
    "            'multi_class' : ['ovr','crammer_singer'],\n",
    "            'fit_intercept' : [True,False],\n",
    "            'random_state': [0,10,20,30],\n",
    "            'max_iter' : [1000,1500],\n",
    "            'C':[1.0,10.0,100.0]\n",
    "        }\n",
    "    elif clfname=='LogisticRegression':\n",
    "          param_grid = { \n",
    "            'random_state': [0,10,20,30],\n",
    "            'max_iter' : [1000,1500],\n",
    "            'multi_class' : ['ovr'],\n",
    "            'tol' : [0.0001,0.0002,0.0003,0.004],\n",
    "            'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "            'fit_intercept' : [True,False],\n",
    "            'C':[1.0,10.0,100.0]\n",
    "        }\n",
    "    elif clfname=='SGDClassifier':\n",
    "        param_grid = { \n",
    "           'alpha':[0.0001,0.0002,0.0005,0.001,0.002],\n",
    "            'fit_intercept' : [True,False],\n",
    "            'n_iter' : [5,10,20,50],\n",
    "            'shuffle' : [True,False],\n",
    "            'random_state': [0,10,20,30],\n",
    "            'warm_start':[True,False]\n",
    "        }\n",
    "    elif clfname=='RidgeClassifier':\n",
    "        param_grid = { \n",
    "            'alpha':[0.0001,0.0002,0.0005,0.001,0.002],\n",
    "            'copy_X':[True,False],\n",
    "            'fit_intercept' : [True,False],\n",
    "            'max_iter' : [500,1000],\n",
    "            'normalize' : [True,False],\n",
    "            'solver': ['auto', 'svd', 'cholesky','lsqr','sparse_cg'],\n",
    "            'tol' : [0.0001,0.0002,0.0003,0.0004],\n",
    "        }\n",
    "    elif clfname=='KNeighborsClassifier':\n",
    "        param_grid = { \n",
    "            'n_neighbors':[5,10,15,20],\n",
    "            'weights':['uniform','distance'],\n",
    "            'algorithm' : ['auto','ball_tree', 'kd_tree','brute'],\n",
    "            'metric':['euclidean','manhattan','chebyshev','minkowski']\n",
    "        }\n",
    "    return param_grid\n",
    "\n",
    "def getClassifierName(clf):\n",
    "    if type(clf).__name__ != 'OneVsRestClassifier':\n",
    "        #print type(clf).__name__\n",
    "        return type(clf).__name__\n",
    "    else:\n",
    "        #print type(clf.estimator).__name__ \n",
    "        return type(clf.estimator).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A function to printResults\n",
    "def printResults(resultpath,clfname,grid_scores,best_params,best_score):\n",
    "    print resultpath+clfname\n",
    "    gridResults=open(resultpath+'_Result_'+clfname+'.txt', 'w')\n",
    "    print \"Grid Scores:\\n\"\n",
    "    gridResults.write(\"Grid Scores:\\n\")\n",
    "    for params, mean_score, scores in grid_scores:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"% (mean_score, scores.std() * 2, params))\n",
    "            gridResults.write(\"\\n%0.3f (+/-%0.03f) for %r\"% (mean_score, scores.std() * 2, params))\n",
    "    print \"\\nBest Score:\\n\"\n",
    "    gridResults.write(\"\\nBest Score:\\n\")\n",
    "    print \"\\nBest Params:\\n\"\n",
    "    gridResults.write(\"\\nBest Params:\\n\")\n",
    "    print best_score\n",
    "    gridResults.write(\"%s\"%(best_score))\n",
    "    print best_params\n",
    "    gridResults.write(\"%s\"%(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dfs=[]\\npath='../data/'\\nonlyfiles = [ f for f in listdir(path) if isfile(join(path,f)) and f.endswith( 'csv' ) ]\\nprint onlyfiles\\nfor eachFile in onlyfiles:\\n    path1='../data/'+eachFile\\n    df1= pd.read_csv(path1,sep=',',header=0)\\n    print df1.shape[0]\\n    dfs.append(df1)\\ndf=pd.concat(dfs)\\ndf.shape[0]\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single file\n",
    "path='/home/ayush/Desktop/BigData_ProjectData/PlayStoreCsv/data/big_data1.csv'\n",
    "df= pd.read_csv(path,sep=',',header=0)\n",
    "\n",
    "#whole data\n",
    "'''dfs=[]\n",
    "path='../data/'\n",
    "onlyfiles = [ f for f in listdir(path) if isfile(join(path,f)) and f.endswith( 'csv' ) ]\n",
    "print onlyfiles\n",
    "for eachFile in onlyfiles:\n",
    "    path1='../data/'+eachFile\n",
    "    df1= pd.read_csv(path1,sep=',',header=0)\n",
    "    print df1.shape[0]\n",
    "    dfs.append(df1)\n",
    "df=pd.concat(dfs)\n",
    "df.shape[0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapBooleanColumns(x):\n",
    "    if x==True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def mappingScores(x):\n",
    "    if x>0 and x<=1:\n",
    "        return 1\n",
    "    elif x>1 and x<=2:\n",
    "        return 2\n",
    "    elif x>2 and x<=3:\n",
    "        return 3\n",
    "    elif x>3 and x<=4:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def mapDates(d):\n",
    "    d=d[:10]\n",
    "    d1= datetime.now()\n",
    "    d2=datetime.strptime(d, \"%Y-%m-%d\")\n",
    "    return (d1.year - d2.year)*12 + d1.month - d2.month    \n",
    "    \n",
    "def seperateInstallations(col_name):\n",
    "    return_data_type_as=None\n",
    "    ls = col_name.str.split('-').str.get(0).str.strip(' ').str.replace(',','') #series object\n",
    "    hs = col_name.str.split('-').str.get(1).str.strip(' ').str.replace(',','') #series object\n",
    "    ls = ls.astype(float).fillna(0.0)\n",
    "    hs = hs.astype(float).fillna(0.0)\n",
    "    return ls, hs\n",
    "\n",
    "def processAppSize(x):\n",
    "    if x==-1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming the data into numerical forms\n",
    "df.IsTopDeveloper=map(mapBooleanColumns,df.IsTopDeveloper)\n",
    "df.HaveInAppPurchases=map(mapBooleanColumns,df.HaveInAppPurchases)\n",
    "df.IsFree=map(mapBooleanColumns,df.IsFree)\n",
    "df.Score=map(mappingScores,df.Score)\n",
    "df.PublicationDate=map(mapDates,df.PublicationDate)\n",
    "df.LastUpdateDate=map(mapDates,df.LastUpdateDate)\n",
    "df['minInstall'],df['maxInstall']=seperateInstallations(df.Instalations)\n",
    "df.AppSize=map(processAppSize,df.AppSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selecting Features\n",
    "df=df.head(n=3000)\n",
    "X=df[['Price','PublicationDate','AppSize','LastUpdateDate','IsFree','HaveInAppPurchases','minInstall','maxInstall']]\n",
    "y=pd.DataFrame(df[['Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formed dataframe of size:( 3000 , 41 )\n",
      "formed dataframe of size:( 3000 , 1261 )\n",
      "formed dataframe of size:( 3000 , 7635 )\n",
      "formed dataframe of size:( 3000 , 7 )\n",
      "formed dataframe of size:( 3000 , 602 )\n"
     ]
    }
   ],
   "source": [
    "# Vectorising the features and merging them to selected numerical features     \n",
    "min_df=1\n",
    "max_df=0.9\n",
    "lowercase=True\n",
    "stem_vectorizer = ATV.StemmedCountVectorizer(encoding='utf-8',\n",
    "                                         min_df =min_df,\n",
    "                                         max_df =max_df,\n",
    "                                         stop_words='english',\n",
    "                                         analyzer='word',\n",
    "                                         lowercase = lowercase)\n",
    "                \n",
    "##set filterparameter to your vectorizer\n",
    "filter_by=[\"OnlyEng\", \"AllLang\"] #two options are available\n",
    "count_dialect = True \n",
    "n_samples = df.shape[0] #as u choose it.\n",
    "stem_vectorizer.setfilter_option(filter_by[1],count_dialect)    \n",
    "# Vectorizing the Category Column\n",
    "nCategory, fmatrix, column_vectorizer = ATV.vectorize_columnTfIdf(df, 'Category', stem_vectorizer,df.shape[0],True)\n",
    "# Vectorizing the Name Column\n",
    "stem_vectorizer.setfilter_option(filter_by[0],count_dialect) \n",
    "nName, fmatrix1, column_vectorizer1 = ATV.vectorize_columnTfIdf(df, 'Name', stem_vectorizer,df.shape[0],True)\n",
    "# Vectorizing the Description Column\n",
    "nDescription, fmatrix2, column_vectorizer2 = ATV.vectorize_columnTfIdf(df, 'Description',stem_vectorizer,df.shape[0],True)\n",
    "# Vectorizing the Content Rating Column\n",
    "nContentRating, fmatrix3, column_vectorizer3 = ATV.vectorize_columnTfIdf(df, 'ContentRating',stem_vectorizer,df.shape[0],True)\n",
    "# Vectorizing the Developer Column\n",
    "nDeveloper, fmatrix3, column_vectorizer3 = ATV.vectorize_columnTfIdf(df, 'Developer',stem_vectorizer,df.shape[0],True)\n",
    "\n",
    "finaldf = pd.concat([X,nCategory,nName,nDescription,nContentRating,nDeveloper],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9554) (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "print finaldf.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processClassifier(X,Y,cl,param_grid,resultpath):\n",
    "    clf = GridSearchCV(estimator=cl, param_grid=param_grid,n_jobs=4,cv=10)\n",
    "    clf.fit(X,Y)\n",
    "\n",
    "    grid_scores=clf.grid_scores_\n",
    "    best_params=clf.best_params_\n",
    "    best_score=clf.best_score_\n",
    "    printResults(resultpath,getClassifierName(cl),grid_scores,best_params,best_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = [RandomForestClassifier(),LogisticRegression(),SGDClassifier(),RidgeClassifier()\n",
    "              ,DecisionTreeClassifier(),KNeighborsClassifier()]\n",
    "\n",
    "xx=finaldf.copy()\n",
    "pca = PCA(n_components=100)\n",
    "xx= pca.fit_transform(xx)\n",
    "yy=y.values\n",
    "for clf in classifiers:\n",
    "    print (\"\\n>> Start Processing %s\"%(getClassifierName(clf)))\n",
    "    param_grid=getParamGrid(clf)\n",
    "    processClassifier(xx,yy.ravel(),clf,param_grid,resultpath)\n",
    "    print (\"\\n>> End Processing %s\"%(getClassifierName(clf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 100)\n"
     ]
    }
   ],
   "source": [
    "print xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 5 ..., 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "print yy.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
